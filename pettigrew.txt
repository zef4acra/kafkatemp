(1) [page 2] RP syas No Drop is "if agent has opinion set {A,B} and A entails B then rationality requires that c(A)=<c(B)." However, rationality does not require that the agent knows that A entails B. Is the agent logically omniscient?

(2) [page 4] RP defines the squared Euclidean distance in terms of atomic propositions, but keeps saying all propositions. Which one is it?

(3) [page 26] the Brier score is proper; is the Kullback-Leibler
Divergence proper?

(4) [page 17] theorem 1.0.2 can't be right the way it stands because
it privileges normalized probability functions

(5) high-level criticism, not just of Pettigrew, but also of Joyce and
de Finetti. When they prove de Finetti's theorem, do they take into
account that a credence function is completely free in choosing any
credence for any proposition in the algebra, not just the atomic
propositions? If there is one event E, then the algebra consists of 4
elements, \emptyset, A, not-A, \Omega. If there are two events A and
B, then there are four atomic propositions which determine any
probability distribution: A and B, A and not-B, not-A and B, not-A and
not-B. The algebra consists of any combination of these atomic
propositions connected by OR, for how to put this in code see
definetti.jl. If n is the number of events under consideration, 2^n is
the number of atomic propositions and 2^(2^n) is the number of
propositions in the algebra. Probabilities are only free over the
atomic propositions; credences are free over the whole algebra. There
are several things I want to know: are there credences that are not
Brier-score-dominated by a single probability distribution given this
more complicated state of affairs? Does de Finetti's proof address
this more complicated state of affairs? Are there credences (which
must be positive to be measurable by DKL) that are not DKL-dominated
by a single probability distribution at each possible world?

(6) [section 4.1] Pettigrew claims that there are no irreducible
global features of inaccuracy. I agree. This, however, does not mean
that global inaccuracy must be the sum of local inaccuracies. It only
means that global inaccuracy is a function of local inaccuracies, and
there are many other functions beside addition that would give us the
local veritism that Wormwood wants.

(7) [page 51] Here is a problem with DKL and local inaccuracy. Let my
credence that a coin toss is H be 0.52. The world w1 at which we measure
my credence's local inaccuracy with respect to this proposition is
such that H is true. Then a local version of inaccuracy for DKL is (?)
1 * log(1/0.52) or -log(0.52). So far so good, except that it
subscribes to regularity in the sense that my inaccuracy is infinite
if I have an extreme credence of zero. However, if at w2 not-H is
true, then my local inaccuracy is 0 * log(0/0.52), which is
conventionally taken to be zero. I wouldn't have been inaccurate at
all! Furthermore, my local inaccuracy for the logically equivalent
proposition not-H, in which, say, I have credence 0.48, is completely
different! Do these problems go away if I model credences as manifolds
and apply the Fisher metric rather than modeling them using Cartesian
coordinates and applying DKL? What Wormwood calls a one-dimensional
divergence does not appear to be straightforward for logarithmic
measures.

(8) [page 83] Why is \mathcal{B}_{\mathcal{F}} restricted to credence
functions that take values between 0 and 1? This may help me because
DKL can't apply to negative numbers or zero. Pettigrew is consistent
here with his definition of credence functions on page 16, definition
1.0.1.

(9) [page 83] What is \mathcal{W}_{\mathcal{F}}? I am assuming it is a
set of worlds which corresponds to whether the propositions in
\mathcal{F} are true or not. \mathcal{F}, according to Pettigrew, is
not necessarily an algebra. A credence function $c$, however, is only
a probability function if it can be extended to a credence function
that is a probability function on an algebra. There is some
circularity in P's definition of what a probability function is in
definition 1.0.1. 

(10) The meat is all in theorem I.A.2. Let's see if we can poke any
holes. Here is the only place I can think of: if $p$ and $p'$ are
probability functions, then so is $\lambda{}p+(1-\lambda)p'$. 


bookmark: page 65, section 4.3






















